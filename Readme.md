
# Customer Support System

## Overview

This project implements a **Customer Support System** with multimodal capabilities, supporting both text and audio interactions. Users can input their queries either by typing or speaking, and the system will respond accordingly with text or audio responses. The system utilizes cutting-edge technologies, including Whisper for speech-to-text transcription, Google Text-to-Speech (gTTS) for audio output, and a Large Language Model (LLM) from Groq (Gemma2-9b-it) for intent classification and response generation.

## Features

- **Multimodal Interaction**: 
  - **Audio Input & Output**: Users can speak their queries, which are transcribed into text using Whisper, and receive audio responses generated by Google Text-to-Speech (gTTS).
  - **Text Input & Output**: Users can also type their queries and receive text-based responses.
- **Speech-to-Text**: Converts spoken language into text using the Whisper model.
- **Intent Classification**: Understands the user's intent from their input and classifies it into predefined categories using the Groq LLM (Gemma2-9b-it).
- **Response Generation**: Generates appropriate responses based on the classified intent.
- **Text-to-Speech**: Converts the AI-generated responses into speech for audio-based interactions.
- **Conversation Memory**: Maintains a conversation history to ensure contextual and coherent interactions.

## Project Structure

- **app.py**: The Streamlit-based web application interface for customer support.
- **fastapi.py**: The FastAPI implementation providing RESTful API endpoints for customer support functionality.
- **utils.py**: A utility module containing shared functions for audio processing, transcription, intent classification, response generation, and text-to-speech conversion.
- **.env**: Environment file for storing sensitive API keys and configuration settings.
- **requirements.txt**: Lists all the Python packages and dependencies required for the project.

## Usage
### Step 1 : 

1.**Create virtual environment**
```bash
python -m venv venv
```
2.**Activate virtual environment**
```bash
venv/scripts/activate
```
2.**Install requirements**
```bash
pip install -r requirements.txt
```
### Step 2: Running the FastAPI Service

1. **Start the FastAPI server:**
   ```bash
   uvicorn fastapi:app --reload
   ```

2. **Access the API documentation:**
   Open your browser and navigate to `http://127.0.0.1:8000/docs` to view the interactive API documentation.

### Step 3: Running the Streamlit App

1. **Start the Streamlit application:**
   ```bash
   streamlit run app.py
   ```

2. **Interact with the web interface:**
   - **Record Audio**: Click on "Start Recording" to input your query via voice. The system will transcribe your speech using Whisper and respond with an audio reply using Google Text-to-Speech.
   - **Text Input**: Type your query in the provided text box and press Enter to receive a text response.


## Known Issues

- **Silence Detection**: The system detects silence and prevents unnecessary processing, but in noisy environments, false positives might occur.
- **Model Latency**: Depending on your hardware, the speech-to-text and response generation may have noticeable latency.



